Static type systems are a marvelous invention.
%
They rule out, at compile-time, an entire class of run-time failures,
\eg dereferencing a |null|-pointer or passing an |int| where a |bool|
was expected.
%
Languages like \ocaml and \haskell make
the value-proposition for types even more
appealing by using constraints to automatically
synthesize the types for all program terms,
without troubling the programmer for any
annotations.
%
Unfortunately, this automation comes at a price.
%
Type annotations signify the programmer's intent, and help to correctly
blame the erroneous sub-term when the code is ill-typed.
%
In the absence of such signifiers, automatic type inference algorithms
are prone to report type errors far from their source
\citep{Wand1986-nw}.
%
While this can seem like a minor annoyance to veteran programmers,
\citet{Joosten1993-yx} have found that novices often focus their
attention on the \emph{location} reported and disregard the
\emph{message}.

In this dissertation we present two new, complementary techniques
designed to help \emph{localize} and \emph{explain} type errors, drawing
inspiration from the fields of automated program testing and machine
learning.
%
In the rest of this chapter we will set the stage for our contributions.
%
First, we will motivate the program of type error diagnosis with a
simple example, and will review the state of the art in type error
diagnosis.
%
% Second, we will provide a brief introduction to automated program
% testing and machine learning.
%
Then, we will outline our novel contributions to the field.


\section{A Running Example}
\label{sec:intro:sumList}

\begin{figure}[t]
\small
\begin{minipage}{0.45\linewidth}
\begin{ecode}
let rec sumList xs =
  match xs with
  | []   -> []
  | h::t -> h + (*@\hlRed{sumList t}@*)
\end{ecode}
\end{minipage}
\begin{minipage}{0.5\linewidth}
\begin{verbatim}
This expression has type 'a list
but an expression was expected of type int
\end{verbatim}
\end{minipage}
\caption{(left) An ill-typed \ocaml program that should sum the elements of a
  list, \hlRed{highlighting} the location blamed by the \ocaml compiler.
  % list, with highlights indicating two possible blame assignments based on:
  %
  % (1) the \hlTree{\ocaml} compiler; and
  % %
  % (2) the student's \hlSherrloc{fix}.
  %
  % The \underline{underlined} expressions are equally valid
  % locations to blame. The expression blamed by the \ocaml compiler
  % is in \textbf{bold}.
  %
  % FIXME: This bolding is ambiguous, because ``let rec'', ``match'' and
  % ``with'' are also bolded (by \\ecode)! You need to find another way to
  % highlight what ocaml is yelling about.
  %
  (right) The error reported by \ocaml.}
\label{fig:intro:sumList}
\end{figure}

Consider the \ocaml program in \autoref{fig:intro:sumList}, which is
supposed to sum the integers in a list.
%
This program was written by an undergraduate student at UC San Diego,
and works as follows.
%
In functional languages like \ocaml, lists are recursively defined as
either the empty list (written |[]| and pronounced ``nil''), or a single
element |h| followed by the rest of the list |t| (written |h::t| and
pronounced ``h cons t'')\footnote{These variable names are conventional,
  \texttt{h} stands for ``head'' and \texttt{t} for ``tail''.}.
%
Given an input |xs|, the student |match|es it against the
two forms a list can take.
%
In the |[]| case she returns another empty list |[]|, and in the
|h::t| case she adds |h| to the recursive sum of |t|.

The observant reader will notice that this program is incorrect, given
\emph{any} non-empty list of integers, the addition on line 4 will
attempt to add an integer to |[]|, which is an invalid operation.
%
In fact, the program is \emph{ill-typed} and the \ocaml compiler rejects
it with the error message in \autoref{fig:intro:sumList}.
%
Unfortunately, \ocaml's error \emph{blames} the recursive call to
|sumList|, explaining that |sumList| returns a |list|, while the |+|
operator requires an |int|.
%
The real error is on line 3, where the student returns |[]| rather than
|0| as the sum of an empty list.

As we will see throughout the rest of this chapter, this rather simple
program is sufficient to illustrate many of the difficulties of
automatically locating the source of a type error, and explaining it to
the programmer.

\section{The Hindley-Milner Type System}
\label{sec:intro:simple-type}

To illustrate the difficulty of pinpointing the source of type errors,
let us consider the simple $\lambda$-calculus in
\autoref{fig:intro:simple-lambda}.
%
In addition to the usual variables, $\lambda$-abstractions, and
applications, we have equipped the language with integers and lists, so
that it can easily represent our |sumList| program.
%
To describe type inference, we will also need type environments and
substitutions.
%
A type environment $\Gamma$ is a mapping from variables to types,
written $\{x_1:t_1, \ldots, x_n:t_n \}$, and denotes that each variable
$x_i$ has type $t_i$.
%
Type environments are used to propagate typing information from outer
expressions to inner expressions. %, \eg the $\lambda$ form will extend the
% current type environment with a new binding for the variable $x$.
%
A substitution is a mapping from \emph{type} variables to concrete
types, written
$\{\alpha_1 \mapsto t_1, \ldots, \alpha_n \mapsto t_n \}$, and denotes
that each type variable $\alpha_i$ has been \emph{refined} to a concrete
type $t_i$.
%
Substitutions are used to propagate typing information from inner expressions
back to the outer expressions.
%
%For example, given the expression $\efun{x}{\eplus{x}{1}}$, we will extend

\begin{figure}
\centering
\[
\boxed{
\begin{array}{rrcl}
\mathbf{Expressions}
& e & ::=    & x \spmid \efun{x}{e} \spmid \eapp{e}{e} \spmid \elet{x}{e}{e} \\
&   & \spmid & n \spmid \eplus{e}{e}\\
    % & \spmid & b \spmid \eif{e}{e}{e} \\
    % & \spmid & \epair{e}{e} \spmid \epcase{e}{x}{x}{e} \\
&   & \spmid & \enil \spmid \econs{e}{e} \spmid \elcase{e}{e}{x}{x}{e} \\[0.05in]

%\mathbf{Numbers}
& n & ::= &  0, 1, -1, \ldots \\[0.2in]

% b & ::= &  \etrue \spmid \efalse \\[0.05in]
\mathbf{Types}
& t & ::= & \alpha \spmid % \tbool \spmid
            \tint \spmid \tarr{t}{t} \spmid % \tprod{t}{t} \spmid
            \tlist{t} \\[0.2in]

\mathbf{Environments}
& \Gamma & ::= &
  \{x_1:t_1, \ldots, x_n:t_n \}
  % \cdot \spmid \Gamma;x:t
\\[0.2in]

\mathbf{Substitutions}
& \sigma & ::= &
  \{\alpha_1 \mapsto t_1, \ldots, \alpha_n \mapsto t_n \}
  % \cdot \spmid \sigma \cup \{\alpha \mapsto t\}
\\
\end{array}
}
\]
\caption{A simple $\lambda$-calculus with integers and lists.}
\label{fig:intro:simple-lambda}
\end{figure}

\ocaml's type system, like many other typed functional languages, is
based on the Hindley-Milner type
system~\citep{Hindley1969-pb,Milner1978-da}, which we have extended to
our language in \autoref{fig:intro:hindley-milner}.
%
The type system is written as a set of inference rules for typing
judgments of the form $\jtype{\Gamma}{e}{t}$, which can be read as ``in
the environment $\Gamma$, the expression $e$ has type $t$.''

As written, this system cannot be used as an algorithm for computing the
type of an expression.
%
For instance, consider the \textsc{Lam} rule.
%
The premise says that $e$ should have type $t_2$ in an environment where
$x$ has type $t_1$, but where did $t_1$ come from?
%
We have no way of knowing at this point what choice of $t_1$ will lead
to a successful type inference, and trying all types is not an option
as there are an infinite number.
%
Thus, a type inference algorithm must defer the choice of $t_1$ until it
has examined the body $e$ to determine how $x$ is used.

\begin{figure}[t]
\begin{framed}
\judgementHead{Typing}{\jtype{\Gamma}{e}{t}}
\begin{gather*}
\inference[\textsc{Var}]
  {x:t \in \Gamma}
  {\jtype{\Gamma}{x}{t}}
\quad
\inference[\textsc{Lam}]
  {\jtype{\Gamma \cup \{x:t_1\}}{e}{t_2}}
  {\jtype{\Gamma}{\efun{x}{e}}{\tarr{t_1}{t_2}}}
\quad
\inference[\textsc{App}]
  {\jtype{\Gamma}{e_1}{\tarr{t_1}{t_2}}
   \quad
   \jtype{\Gamma}{e_2}{t_1}}
  {\jtype{\Gamma}{\eapp{e_1}{e_2}}{t_2}}
\\[0.1in]
\inference[\textsc{Let}]
  {\jtype{\Gamma}{e_1}{t_1}
   \quad
   \jtype{\Gamma \cup \{x:t_1\}}{e_2}{t_2}}
  {\jtype{\Gamma}{\elet{x}{e_1}{e_2}}{t_2}}
\\[0.1in]
\inference[\textsc{Lit}]
  {}
  {\jtype{\Gamma}{n}{\tint}}
\quad
\inference[\textsc{Plus}]
  {\jtype{\Gamma}{e_1}{\tint} \quad \jtype{\Gamma}{e_2}{\tint}}
  {\jtype{\Gamma}{\eplus{e_1}{e_2}}{\tint}}
\\[0.1in]
\inference[\textsc{Nil}]
  {\alpha \text{ is fresh}}
  {\jtype{\Gamma}{\enil}{\tlist{\alpha}}}
\quad
\inference[\textsc{Cons}]
  {\jtype{\Gamma}{e_1}{t} \quad \jtype{\Gamma}{e_2}{\tlist{t}}}
  {\jtype{\Gamma}{\econs{e_1}{e_2}}{\tlist{t}}}
\\[0.1in]
\inference[\textsc{Match}]
  {\jtype{\Gamma}{e_1}{t_1}
    \quad
   \jtype{\Gamma}{e_2}{t_2}
    \quad
   \jtype{\Gamma \cup \{x_1:t_1,\ x_2:\tlist{t_1}\}}{e_3}{t_2}
  }
  {\jtype{\Gamma}{\elcase{e_1}{e_2}{x_1}{x_2}{e_3}}{t_2}}
\end{gather*}
\end{framed}
\caption{A Hindley-Milner-style type system for the language in \autoref{fig:intro:simple-lambda}.
  %
  % This
  % language lacks common features like recursion and polymorphic
  % functions since they do not
  We omit the usual rules for generalization and instantiation of type
  schemes since they do not have a significant effect on the location or
  content of type errors.  
}
\label{fig:intro:hindley-milner}
\end{figure}

\begin{figure}[p]
\centering
\[
\boxed{
\begin{array}{lcl}
\W & : & \Gamma \times e \rightarrow \sigma \times t
\\[0.1in]
\W(\Gamma, x)
   & = & (\cdot, t) \quad \text{ where } \Gamma(x) = t
\\[0.05in]
\W(\Gamma, \efun{x}{e})
   & = & \text{let } (\sigma, t) = \W(\Gamma \cup \{x:\alpha\}, e),\ \alpha \text{ is fresh} \\
   &   & \text{in  } (\sigma, \sigma(\tarr{\alpha}{t}))
\\[0.05in]
\W(\Gamma, \eapp{e_1}{e_2})
   & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
   &   & \quad\ (\sigma_2, t_2) = \W(\sigma_1(\Gamma), e_2) \\
   &   & \quad\ \sigma_3 = \U(\sigma_2(t_1),\tarr{t_2}{\alpha}),\ \alpha \text{ is fresh} \\
   &   & \text{in } (\sigma_3(\sigma_2(\sigma_1)), \sigma_3(\alpha))
\\[0.05in]
\W(\Gamma, \elet{x}{e_1}{e_2})
   & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
   &   & \quad\ \Gamma' = \Gamma \cup \{x_1:t_1\} \\
   &   & \quad\ (\sigma_2, t_2) = \W(\sigma_1(\Gamma'), e_2) \\
   &   & \text{in } (\sigma_2(\sigma_1), t_2)
\\[0.05in]
\W(\Gamma, n)
   & = & (\cdot, \tint)
\\[0.05in]
\W(\Gamma, \eplus{e_1}{e_2})
   & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
   &   & \quad\ (\sigma_2, t_2) = \W(\sigma_1(\Gamma), e_2) \\
   &   & \quad\ \sigma_3 = \U(t_1,\tint) \\
   &   & \quad\ \sigma_4 = \U(t_2,\tint) \\
   &   & \text{in } (\sigma_4(\sigma_3(\sigma_2(\sigma_1))), \tint)
\\[0.05in]
\W(\Gamma, \enil)
   & = & (\cdot, \tlist{\alpha}), \quad \alpha \text{ is fresh}
\\[0.05in]
\W(\Gamma, \econs{e_1}{e_2})
   & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
   &   & \quad\ (\sigma_2, t_2) = \W(\sigma_1(\Gamma), e_2) \\
   &   & \quad\ \sigma_3 = \U(t_2,\sigma_2(\tlist{t_1})) \\
   &   & \text{in } (\sigma_3(\sigma_2(\sigma_1)), \sigma_3(\tlist{t_1}))
\\[0.05in]
\W(\Gamma, \elcase{e_1}{e_2}{x_1}{x_2}{e_3})
   & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
   &   & \quad\ \sigma_2 = \U(t_1,\tlist{\alpha}),\ \alpha \text{ is fresh} \\
   &   & \quad\ (\sigma_3, t_2) = \W(\sigma_2(\Gamma), e_2) \\
   &   & \quad\ \Gamma' = \Gamma \cup \{x_1:\alpha,\ x_2:\tlist{\alpha}\} \\
   &   & \quad\ (\sigma_4, t_3) = \W(\sigma_3(\sigma_2(\Gamma')), e_3) \\
   &   & \quad\ \sigma_5 = \U(t_2,\sigma_4(t_1)) \\
   &   & \text{in } (\sigma_5(\sigma_4(\sigma_3(\sigma_2(\sigma_1)))), \sigma_5(t_1)) \\
\end{array}
}
\]
\caption{Algorithm $\mathcal{W}$~\citep{Damas1982-uw}, adapted to our language. \ES{TODO: CHECK THE NEW RULES}}
\label{fig:intro:algo-w}
\end{figure}

The traditional Damas-Milner Algorithm
$\mathcal{W}$~\citep{Damas1982-uw}, extended to our language in
\autoref{fig:intro:algo-w}, solves this issue by binding $x$ to a fresh
type variable $\alpha$ (\ie one that does not occur in the environment).
%
It takes as input a typing environment $\Gamma$ and an expression $e$,
and returns a substitution $\sigma$ and an inferred type $t$.
%
In the $\lambda$ case, it then applies the substitution to the function
type $\tarr{\alpha}{t}$ before returning it, crucially refining $\alpha$
based on the body of the lambda.

A key component of Algorithm \W is Robinson's unification algorithm,
\U~\citep{Robinson1965-rk}, which takes two types $t_1$ and $t_2$ and
returns a substitution $\sigma$ such that $\sigma(t_1) = \sigma(t_2)$.
%
For example,
$\U(\tarr{\alpha_1}{\tint},\ \tarr{\tlist{\tint}}{\alpha_2}) = \{\alpha_1 \mapsto \tlist{\tint},\ \alpha_2 \mapsto \tint\}$.
%
It is the combination of fresh type variables to defer the choice of
concrete types and Robinson's \U to instantiate them that allows \W to
efficiently compute the type of an expression without any user
annotations.

Unfortunately, that is also precisely the source of the poor error
messages associated with type inference.
%
Unification is not guaranteed to succeed, \eg there is no substitution
of type variables that would unify $\tint$ and $\tlist{\tint}$.
%
\W traverses the program from the bottom up, collecting
typing constraints at each expression, and halts with an error when it
detects an inconsistent constraint during a call to \U.
%
Thus, the placement of calls to $\U$ determines which expression
will be blamed when a program is ill-typed.

Given our |sumList| program \W will infer that the |[]| case
returns a list while the |h::t| case returns an integer, which violates
the \textsc{Match} rule's constraint that both branches must have the
same type $t_2$.
%
This violation will manifest as an error in the second $\U$
call in \W's |match| case, and \W will thus blame
% $\mathcal{W}$ will then \emph{blame} the expression that induced the
% inconsistent constraint, in this case
the entire |match| expression
even though the error was in the base case.

In this case $\mathcal{W}$'s error report is actually not so
bad, a well-written error message could convey that the error is due to
the two branches having different types, which may be sufficient to
isolate the source in the base case.
%
But in general, this behavior of bubbling up of typing constraints from
the leaves of the program can produce very poor errors~\citep[see
Fig. 1 for a particularly pathological example]{Lee1998-ys}.


\section{Prior Work on Diagnosing Type Errors}
\label{sec:diagnosing-type-errors}
Algorithm \W's poor error reports were noticed soon after its
introduction~\citep{Wand1986-nw}, and improving them has been a popular
area of research ever since.
%
In this section we will review the state of the art in type error
diagnosis according to the following three high-level approaches:
\begin{enumerate}
\item \emph{localizing} errors to a specific (set of) term(s);
\item \emph{explaining} the error to the programmer; and
\item automatically \emph{fixing} the error for the programmer.
\end{enumerate}

\subsection{Localizing Type Errors}
\label{sec:localizing-type-errors}
The location reported by a type error is likely to be the first place
the programmer looks for issues, so providing an accurate %source
location could greatly reduce the time spent debugging.

\paragraph{Alternate Traversal Strategies}
Noting that the placement of unification calls determines where errors
are reported, several authors have proposed alternate traversal
strategies.
%
\citet{Lee1998-ys} describe a ``folklore'' algorithm $\mathcal{M}$ that
traverses the program top down, rather than from the bottom up, pushing
constraints inward from outer expressions.
%
Thus, while \W returned both a substitution and a type, \M takes an
\emph{expected} type as input, and returns only a substitution.
%
\citeauthor{Lee1998-ys} also prove that \M always terminates sooner that
$\mathcal{W}$ would, \ie at an expression deeper in the tree.
%
\begin{figure}
\centering
\[
\boxed{
\begin{array}{lcl}
\M & : & \Gamma \times e \times t \rightarrow \sigma \\
% \W(\Gamma, x)
%    & = & (\cdot, t) \quad \text{ where } \Gamma(x) = t \\
% \W(\Gamma, \efun{x}{e})
%    & = & \text{let } (\sigma, t) = \W(\Gamma;x:\alpha, e),\ \alpha \text{ is fresh} \\
%    &   & \text{in  } (\sigma, \sigma(\tarr{\alpha}{t})) \\
% \W(\Gamma, \eapp{e_1}{e_2})
%    & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
%    &   & \quad\ (\sigma_2, t_2) = \W(\sigma_1(\Gamma), e_2) \\
%    &   & \quad\ \sigma_3 = \unify{\sigma_2(t_1)}{\tarr{t_2}{\alpha}},\ \alpha \text{ is fresh} \\
%    &   & \text{in } (\sigma_3(\sigma_2(\sigma_1)), \sigma_3(\alpha)) \\
% \W(\Gamma, \elet{x}{e_1}{e_2})
%    & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
%    &   & \quad\ \Gamma' = \Gamma;\ x_1:t_1 \\
%    &   & \quad\ (\sigma_2, t_2) = \W(\sigma_1(\Gamma'), e_2) \\
%    &   & \text{in } (\sigma_2(\sigma_1), t_2) \\
% \W(\Gamma, n)
%    & = & (\cdot, \tint) \\
\M(\Gamma, \eplus{e_1}{e_2}, t)
   & = & \text{let } \sigma_1 = \U(t,\tint) \\
   &   & \quad\ \sigma_2 = \M(\sigma_1(\Gamma), e_1, \tint) \\
   &   & \quad\ \sigma_3 = \M(\sigma_2(\sigma_1(\Gamma)), e_2, \tint) \\
   &   & \text{in } \sigma_3(\sigma_2(\sigma_1)) \\
% \W(\Gamma, \enil)
%    & = & (\cdot, \tlist{\alpha}), \quad \alpha \text{ is fresh} \\
% \W(\Gamma, \econs{e_1}{e_2})
%    & = & \text{let } (\sigma_1, t_1) = \W(\Gamma, e_1) \\
%    &   & \quad\ (\sigma_2, t_2) = \W(\sigma_1(\Gamma), e_2) \\
%    &   & \quad\ \sigma_3 = \unify{t_2}{\sigma_2(\tlist{t_1})} \\
%    &   & \text{in } (\sigma_3(\sigma_2(\sigma_1)), \sigma_3(\tlist{t_1})) \\
\M(\Gamma, \elcase{e_1}{e_2}{x_1}{x_2}{e_3}, t)
   & = & \text{let } \sigma_1 = \M(\Gamma, e_1, \tlist{\alpha_1}), \alpha_1 \text{ is fresh} \\
   &   & \quad\ \sigma_2 = \M(\sigma_1(\Gamma), e_2, \alpha_2), \alpha_2 \text{ is fresh} \\
   &   & \quad\ \Gamma' = \Gamma \cup \{x_1:\alpha_1,\ x_2:\tlist{\alpha_1}\} \\
   &   & \quad\ \sigma_3 = \M(\sigma_2(\sigma_1(\Gamma')), e_3, \sigma_2(\alpha_2)) \\
   &   & \text{in } \sigma_3(\sigma_2(\sigma_1)) \\
\end{array}
}
\]
\caption{A selection of rules from algorithm \M~\citep{Lee1998-ys},
  extended to our language.}
\label{fig:intro:algo-m}
\end{figure}

\autoref{fig:intro:algo-m} contains a selection of \M's rules that are relevant to the error in our |sumList| program.
%
Note how the |match| rule no longer does any unification, it just makes
a series of recursive calls.
%
Rather, the |+| rule is now responsible for checking that its
surrounding context expects it to return an $\tint$.
%
Crucially, \M \emph{infers} a type for the |[]| case\footnote{Note how
  we pass a fresh type variable $\alpha_2$ as the ``expected'' type.}
and then checks that the |::| case returns the same type.
%
This is a subtle change from \W's behavior, but as a result \M will
blame the |+| expression for producing an $\tint$ rather than the
|match| expression.
%
This is better, though still not ideal as the actual error is in the
|[]| case.

% It pushes typing constraints inward from the outer expressions, \eg when
% checking the |match| expression in |sumList|, it would infer that the
% |[]| branch is a list and would then check that the |h::t| branch is
% also a list.
%
% This is a subtle but crucial change from $\mathcal{W}$, as $\mathcal{M}$
% will abort when it checks that the |+| expression is a list.

Another issue, present in both algorithm $\mathcal{M}$ and
$\mathcal{W}$, is that constraints are propagated from one branch to
others, known as the ``left-to-right'' bias~\citep{McAdam1998-ub}.
%
This bias is the reason that $\mathcal{M}$ (and most type-checkers in
practice) blames the |h::t| case rather than the |[]| case; however,
it is not limited to expressions that create a branch in the program's
control-flow.
%
Rather, the constraint propagation happens between branches of the
program's abstract syntax tree.
%
See, \eg the $\eapp{e_1}{e_2}$ case of \W\ --- we apply the substitution
$\sigma_1$ from $e_1$ to the environment when checking $e_2$.
%
Thus, any expression with multiple children will be subject to the
left-to-right bias.

Instead of propagating the constraints collected in one branch to
others, \citet{McAdam1998-ub} and \citet{Yang1999-yr} suggest a
\emph{symmetric} traversal that checks each branch independently of the
others and then reports an error when merging two inconsistent sets of
constraints from the branches.
%
Mechanically, this means that we no longer apply the substitution from
one branch to the other, but rather unify the substitutions from both
branches after they have been individually checked.
%
One might think we would then be right back at the issue we observed
with algorithm $\mathcal{W}$, with an error reported at the |match|
expression, but \citeauthor{Yang1999-yr} annotates each constraint with
its source location, so that they can report the conflict between the
|[]| on line 3 and the |+| on line 4.

\paragraph{Type Error Slicing}
\citet{Tip2001-qp} and \citet{Haack2003-vc} extend the idea of
\citeauthor{McAdam1998-ub} and \citeauthor{Yang1999-yr}, and compute a
full type error \emph{slice}, \ie all of the sub-expressions that are
required for the error to manifest and no more.
%
For example, one type error slice for |sumList| would be the |match|
expression and its two children, the |[]| and the |+| expression,
which \cite{Haack2003-vc} would report as follows:
%
\begin{verbatim}
  Type error: type constructor clash, endpoints list vs. int.
  match .. with | [] -> [] | h::t -> .. + ..
\end{verbatim}
%
There is at least one other error slice for |sumList|, which includes
the |[]|, the |+|, the recursive |sumList| call, and the |let rec|
binder, which captures the issue that a list can be passed back through
the recursive call to the |+| operator.
%
In general there may be many distinct error slices for the same error,
and while computing one slice can be done efficiently,
computing all slices is exponential.

\citet{Neubauer2003-xv} present a decidable type system based on
discriminative sum types, in which all terms are typeable and type
derivations contain all type errors in a program. They then use the
typing derivation to slice out the parts of the expression related to
each error.
%
\citet{Rahli2010-ps,Rahli2015-tt} investigate what is required to
support slicing for a full programming language, and presetn a type
error slicer for the entirety of \textsc{SML}.
%
\citet{Sagonas2013-bf} use type error slices to explain errors in the
optional \textsc{Dialyzer}~\citep{Lindahl2006-hz} system for
\textsc{Erlang}.
%
\citet{Schilling2011-yf} shows how to how to turn any type checker
into a slicer by treating it as a black-box.

A drawback of type error slicers is that they typically involve
rewriting the type checker to use a specialized constraint language and
solver.
%
Production compilers for languages like \ocaml and \haskell generally
feature more advanced type languages than Hindley-Milner with heavily
optimized type checkers, so the prospect of a full rewrite to support
slicing is probably quite daunting.
%
% The only type error slicer we are aware of that claims to support a full
% language is the \textsc{Skalpel} slicer for
% \textsc{SML}~\citep{Rahli2010-ps,Rahli2015-tt}, though
% \citet{Schilling2011-yf} has shown how to how to turn any type checker
% into a slicer by treating it as a black-box.

Further, while type error slicers can guarantee enough information to
diagnose an error, they can fall into the opposite trap of providing
\emph{too much} information, producing a slice that is not much smaller
than the original program.
%
In other words, a type error slicer will produce \emph{every possible}
expression that could be blamed for the error, but some expressions are
more likely to be at fault than others.

\paragraph{Finding Likely Sources of Errors}
Thus, recent work has focused on finding the \emph{most likely} source
of a type error.
%
\citeauthor{Zhang2015-yu}~\citep{Zhang2014-lv,Zhang2015-yu} use Bayesian
reasoning to search the constraint graph for constraints that
participate in many unsatisfiable paths and relatively few satisfiable
paths, based on the intuition that the program should be mostly correct.
%
\citet{Pavlinovic2014-mr,Pavlinovic2015-kh} translate the localization
problem into a MaxSMT problem, asking an off-the-shelf solver to find
the smallest set of constraints that can be removed such that the
resulting system is satisfiable.
%
\citet{Loncaric2016-uk} improve the scalability of
\citeauthor{Pavlinovic2014-mr} by reusing the existing type checker as
a theory solver in the Nelson-Oppen~\citep{Nelson1979-td}
style, and thus require only a MaxSAT solver.
%
All three of these techniques support \emph{weighted} constraints to
incorporate knowledge about the frequency of different errors,
but only \citeauthor{Pavlinovic2014-mr} use the weights, setting them to
the size of the term that induced the constraint.

Of these three techniques, only \citeauthor{Pavlinovic2014-mr} can
isolate the source of the type error in |sumList| to the |[]| case, as
they weight constraints by expression size.
%
\citeauthor{Zhang2015-yu} and \citeauthor{Loncaric2016-uk} cannot
distinguish between the erroneous |[]| and the correct |+|, and present
both as equally likely sources.


\subsection{Explaining Type Errors}
\label{sec:explaining-type-errors}
The techniques we have discussed so far have focused primarily on the
task of \emph{localizing} a type error, but a good error report should
also \emph{explain} the error.
%
\citet{Wand1986-nw}, \citet{Beaven1993-hb}, and \citet{Duggan1996-by}
attempt to explain type errors by collecting the chain of inferences
made by the type checker --- essentially the typing derivation ---
and presenting them to the user.
%
For example, an explanation of the error in |sumList| in the style of
\citeauthor{Beaven1993-hb} might look like the following:
%
\begin{verbatim}
  A type error was detected in the case analysis of >> xs <<.
  The types of the two branches,
  >> 'a list << and >> int <<,
  are not unifiable.
  ** Why does the >> [] << branch have type >> 'a list << ?
     The expression >> [] << has type >> 'a list << .
  ** Why does the >> h::t << branch have type >> int << ?
     The >> + << operator returns a value of type >> int << .
\end{verbatim}
%
Such explanations, when presented in natural language, can become quite
lengthy.
%
As an attempt to compress the explanation \citet{Yang2000-kz} present a
visualization of the inference process.
%
\citet{Gast2004-zd} produces a slice enhanced by arrows
showing the dataflow from sources with different types to a
shared sink, borrowing the insight of dataflows-as-explanations from
\textsc{MrSpidey}~\citep{Flanagan1996-bu}.

\paragraph{Interactive Explanations}
\emph{Static} explanations of type errors, as seen above, run the risk
of overwhelming the user with too much information, it may be preferable
to treat type error diagnosis as an \emph{interactive} debugging
session.
%
\citet{Bernstein1995-yj} extend the type inference procedure to handle
\emph{open} expressions (\ie with unbound variables).
%
This allows users to interactively query the type checker for the types
of sub-expressions.
%
Thus, a user may be able to quickly examine the expressions she believes
to be relevant rather than having to sift through a static explanation.

Still, the user may have a fundamental misunderstanding of the type
system, leading her to engage in a long series of queries that are not actually relevant to the error.
%
As a remedy, \citet{Chitil2001-td} proposes \emph{algorithmic debugging}
of type errors, presenting the user with a sequence of yes-or-no
questions about the inferred types of sub-expressions.
%
Thus, she will be guided by the system to a specific explanation for the
error in a finite amount of time.

\paragraph{Programmatic Explanations}
%
The best explanation of a type error, however, might be given by an
expert, \eg the compiler or library author.
%
\citet{Hage2006-hc} catalog a set of heuristics for
improving the quality of error messages by examining errors made by
novices.
%
\citet{Marceau2011-ok,Marceau2011-cy} study the effectiveness of error
messages in novice environments and present suggestions for improving
their quality and consistency.
%
\citet{Heeren2003-db}, \citet{Christiansen2014-qc}, and
\citet{Serrano2016-oo} extend the ability to customize error messages to
library authors, enabling \emph{domain-specific} errors.
%
The 8.0 release of the
Glasgow Haskell Compiler\footnote{\url{https://ghc.haskell.org/trac/ghc/wiki/Proposal/CustomTypeErrors}}
incorporates these ideas, allowing library authors to supply
custom errors when type-class resolution or type-family reduction fail,
but not for ordinary unification failures.

\subsection{Fixing Type Errors}
\label{sec:fixing-type-errors}
Finally, some techniques go beyond explaining or locating a type error,
and actually attempt to \emph{fix} the error automatically.
%
\citet{Lerner2007-dt} searches for fixes by enumerating a
set of local mutations to the program and querying the type checker to
see if the error remains.
%
\citet{Chen2014-gd} use a notion of \emph{variation-based} typing to
track choices made by the type checker and enumerate potential
% type (and expression)
changes that would fix the error.
%
They also extend the algorithmic debugging technique of
\citeauthor{Chitil2001-td} by allowing the user to enter the expected
type of specific sub-expressions and suggesting fixes based on these
desired types \citep{Chen2014-vm}.

%\input{intro.testing.tex}

% \section{Machine Learning}
% \label{sec:machine-learning}

% \ES{TODO}

\section{Our Contributions}
\label{sec:our-contributions}

The thesis of this dissertation is that we can adapt the wealth of work
in automated program testing and machine learning to the task of
providing better diagnostic information for type errors.
%
To that end we present three concrete contributions:
%
\begin{enumerate}
\item In Chapter~\ref{chp:data-collection} we present a dataset of
  novice interactions with the \ocaml type checker, which will form the
  backbone of our evaluation.
  %
  This dataset contains thousands of ill-typed programs from over one
  hundred different students, the largest set of novice type errors we
  are aware of.
  % We gathered these interactions from students in an undergraduate
  % course at UC San Diego over the course of two quarters of instruction.
\item In Chapter~\ref{chp:nanomaly} we use techniques from automated
  program testing to search for \emph{witnesses} to type errors, \ie
  input vectors that would cause the program to crash.
  %
  Once we have found a witness, we compute an execution trace that
  \emph{demonstrates} how the program goes wrong, and provide an
  interactive debugger with which students can explore the erroneous
  computation.

\item In Chapter~\ref{chp:nate} we use machine learning techniques to
  \emph{learn} a model of where type errors are most likely to occur in
  our students' programs.
  %
  This model allows us to make significantly more accurate predictions
  of where the error is most likely to be found.
\end{enumerate}

Our contributions are presented and evaluated in the context of \ocaml
programs written by novice programmers, but they are not restricted to
this domain.
%
Rather, we chose \ocaml as the target language as it has a powerful type
system with global inference, showcasing both the advantages of static
typing and the limitations of type inference.
%
We use novice programs for our benchmarks as we feel novices are the
most in need of assistance in diagnosing type errors.
%
In our experience, working with the type system is quite pleasant
once you have gotten used to it; however, getting to that point can be
difficult.
%
% We will note specific limitations of our techniques and describe
% potential remedies in the relevant chapters.

\section*{Endnotes}
\paragraph{Acknowledgments}
This chapter contains material adapted from the following publications:
\begin{itemize}
\item \fullcite{Seidel2016-ul}
\item \fullcite{Seidel2017-gw}
\item \fullcite{Seidel2017-pj}
\end{itemize}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
